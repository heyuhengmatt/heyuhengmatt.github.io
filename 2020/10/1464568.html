<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Python滤镜和图像风格迁移 | Kevin's Space</title><meta name="keywords" content="python,filter"><meta name="author" content="Kevin Matt,he_yuheng@163.com"><meta name="copyright" content="Kevin Matt"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="本文尚未完成XD  关于神经网络的初步学习笔记在这里  Python滤镜和图像风格迁移   任务一  1.了解滤波器 在百度百科中寻找“图像滤波器”会得到一段看起来非常让人困惑的文字：  由于成像系统、传输介质和记录设备等的不完善，数字图像在其形成、传输记录过程中往往会受到多种噪声的污染。另外，在图像处理的某些环节当输入的像对象并不如预想时也会在结果图像中引入噪声。这些噪声在图像上常表现为一引起较">
<meta property="og:type" content="article">
<meta property="og:title" content="Python滤镜和图像风格迁移">
<meta property="og:url" content="https://heyuhengmatt.github.io/2020/10/1464568.html">
<meta property="og:site_name" content="Kevin&#39;s Space">
<meta property="og:description" content="本文尚未完成XD  关于神经网络的初步学习笔记在这里  Python滤镜和图像风格迁移   任务一  1.了解滤波器 在百度百科中寻找“图像滤波器”会得到一段看起来非常让人困惑的文字：  由于成像系统、传输介质和记录设备等的不完善，数字图像在其形成、传输记录过程中往往会受到多种噪声的污染。另外，在图像处理的某些环节当输入的像对象并不如预想时也会在结果图像中引入噪声。这些噪声在图像上常表现为一引起较">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201018143620.png">
<meta property="article:published_time" content="2020-10-14T02:58:04.000Z">
<meta property="article:modified_time" content="2020-10-18T06:08:04.000Z">
<meta property="article:author" content="Kevin Matt">
<meta property="article:tag" content="python">
<meta property="article:tag" content="filter">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201018143620.png"><link rel="shortcut icon" href="/img/favicon.jpg"><link rel="canonical" href="https://heyuhengmatt.github.io/2020/10/1464568"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: {"limitDay":10,"position":"top","messagePrev":"这篇文章已经有","messageNext":"天没有更新，其中的内容可能已经过时。"},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: Kevin Matt","link":"链接: ","source":"来源: Kevin's Space","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  ClickShowText: {"text":"D,K","fontSize":"15px"},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#121212","position":"bottom-left"},
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  isPhotoFigcaption: true,
  islazyload: true,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: true,
  isToc: true,
  postUpdate: '2020-10-18 14:08:04'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
   if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }
  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified
    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }})()</script><link rel="stylesheet" href="/css/background.css"><link rel="stylesheet" href="/css/transp.css"><link rel="stylesheet" href="/css/roll.css"><style type="text/css">#toggle-sidebar {left:100px}</style><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/StaticFile_HEXO@latest/butterfly/css/macblack.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/StaticFile_HEXO@latest/butterfly/css/tags.css"><link href="https://fonts.font.im/css?family=Nunito:700" rel="stylesheet"><link href="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/Hexo/css/hideCategory.min.css" rel="stylesheet"><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.2.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" data-lazy-src="https://s1.ax1x.com/2020/10/11/067U1A.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">17</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">24</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文档</span></a></div><div class="menus_item"><a class="site-page" href="/artitalk/"><i class="fa-fw fas fa-comment"></i><span> 说说</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201018143620.png)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Kevin's Space</a></span><span id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文档</span></a></div><div class="menus_item"><a class="site-page" href="/artitalk/"><i class="fa-fw fas fa-comment"></i><span> 说说</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><h1 class="post-title">Python滤镜和图像风格迁移</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2020-10-14T02:58:04.000Z" title="发表于 2020-10-14 10:58:04">2020-10-14</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2020-10-18T06:08:04.000Z" title="更新于 2020-10-18 14:08:04">2020-10-18</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a></span></div><div class="meta-secondline"> <span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">5.9k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>23分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><div class="note warning icon flat"><p>本文尚未完成XD</p>
</div>
<p>关于神经网络的初步学习笔记在<a target="_blank" rel="noopener" href="https://www.kevinmatt.top/2020/10/18/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0/#1%E4%BB%80%E4%B9%88%E6%98%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">这里</a></p>
<h1 id="python滤镜和图像风格迁移"><a class="markdownIt-Anchor" href="#python滤镜和图像风格迁移"></a> Python滤镜和图像风格迁移</h1>
<img src= "/img/loading.gif" data-lazy-src="https://i.loli.net/2020/10/14/DohYj4NOkUwauXQ.png" alt="来自Jotang的题目" style="zoom:50%;" />
<h2 id="任务一"><a class="markdownIt-Anchor" href="#任务一"></a> 任务一</h2>
<h3 id="1了解滤波器"><a class="markdownIt-Anchor" href="#1了解滤波器"></a> 1.了解滤波器</h3>
<p>在百度百科中寻找“图像滤波器”会得到一段看起来<strong>非常让人困惑</strong>的文字：</p>
<blockquote>
<p>由于成像系统、传输介质和记录设备等的不完善，数字图像在其形成、传输记录过程中往往会受到多种噪声的污染。另外，在图像处理的某些环节当输入的像对象并不如预想时也会在结果图像中引入噪声。这些噪声在图像上常表现为一引起较强视觉效果的孤立像素点或像素块。一般，噪声信号与要研究的对象不相关它以无用的信息形式出现，扰乱图像的可观测信息。对于<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F">数字图像</a>信号，噪声表为或大或小的极值，这些极值通过加减作用于图像像素的真实<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E7%81%B0%E5%BA%A6%E5%80%BC">灰度值</a>上，对图像造成亮、暗点干扰，极大降低了图像质量，影响<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E5%9B%BE%E5%83%8F%E5%A4%8D%E5%8E%9F">图像复原</a>、分割、<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96">特征提取</a>、图像识别等后继工作的进行。要构造一种有效抑制噪声的滤波器必须考虑两个基本问题：能有效地去除目标和背景中的噪声;同时，能很好地保护图像目标的形状、大小及特定的几何和拓扑结构特征  。</p>
</blockquote>
<p>理解图像滤波器概念，其实质有二：</p>
<h4 id="一-图像本质上就是各种色彩波的叠加"><a class="markdownIt-Anchor" href="#一-图像本质上就是各种色彩波的叠加"></a> 一、<strong>图像本质上就是各种色彩波的叠加</strong></h4>
<p>图像在计算机里是按照每个位置的像素值存储的，每个像素的颜色，可以用红、绿、蓝、透明度四个值描述，大小范围都是<code>0 ～ 255</code>，比如黑色是<code>[0, 0, 0, 255]</code>，白色是<code>[255, 255, 255, 255]</code>。(也就是我们常用的rgba)</p>
<p>把每一行的像素的rgb值以折线形式绘制出来，就会得到一段图像：</p>
<img src= "/img/loading.gif" data-lazy-src="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201014114224.png" alt="图源来自网络" style="zoom:67%;" />
<p><strong>所以可以理解为：图像就是色彩的波动：波动大，就是色彩急剧变化；波动小，就是色彩平滑过渡。</strong></p>
<p>而滤波器的功能，就是将这些波动的变化进行削弱或者放大，例如物理中的：</p>
<blockquote>
<ul>
<li>
<p><a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E4%BD%8E%E9%80%9A%E6%BB%A4%E6%B3%A2">低通滤波器</a>（lowpass）：减弱或阻隔高频信号，保留低频信号</p>
</li>
<li>
<p><a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E9%AB%98%E9%80%9A%E6%BB%A4%E6%B3%A2">高通滤波器</a>（highpass）：减弱或阻隔低频信号，保留高频信号</p>
</li>
</ul>
</blockquote>
<p>低通滤波器过滤高频信号，曲线将变得平滑；高通滤波器放大了高频信号，曲线保留下曲折尖锐的部分</p>
<p>在图像中的表现则是：</p>
<ul>
<li>
<p>低通滤波器：图像变得模糊（锐度下降）</p>
<img src= "/img/loading.gif" data-lazy-src="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201014115512.jpeg" alt="图像对比1" style="zoom:67%;" />
</li>
<li>
<p>高通滤波器：图像只剩下锐度极高的部分，其他部分的色彩丢失</p>
<img src= "/img/loading.gif" data-lazy-src="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201014115520.jpeg" alt="图像对比2" style="zoom:67%;" />
<p>虽然实际应用的滤镜比单纯的高通低通滤波器复杂，但本质上应该也是附加规则的高低通滤波器的组合。</p>
</li>
</ul>
<h4 id="二-理解卷积算法"><a class="markdownIt-Anchor" href="#二-理解卷积算法"></a> 二、理解卷积算法</h4>
<p><strong>PIL</strong>库中的滤镜算法主要涉及到卷积滤镜，即在数字图像的像素矩阵中使用一个n*n的矩阵来滤波(该矩阵即卷积核kernal)，以这个矩阵为单位对图像像素进行遍历，每个输出的像素都是区域像素按照一定权重组合计算出的结果，遍历之后输出的图像就是输出的图像。(即依据“规则”通过每个像素点附近的像素值来修改当前像素点的值，遍历修改后就完成了滤波)</p>
<p><img src= "/img/loading.gif" data-lazy-src="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201015142211.gif" alt="实现原理图(来自网络)" /></p>
<p><code>这张Gif很好的描述了卷积算法的过程，所以被我偷了下来，嘻嘻</code></p>
<h3 id="2尝试使用现成的滤波器"><a class="markdownIt-Anchor" href="#2尝试使用现成的滤波器"></a> 2.尝试使用现成的滤波器</h3>
<p>阅读Doc容易发现，在<strong>python</strong>的<strong>PIL</strong>库中，<strong>ImageFilter</strong>类下有许多滤波器可以使用：</p>
<blockquote>
<p><strong>• BLUR</strong>：模糊滤波</p>
<p><strong>• CONTOUR</strong>：轮廓滤波</p>
<p><strong>• DETAIL</strong>：细节滤波</p>
<p><strong>• EDGE_ENHANCE</strong>：边界增强滤波</p>
<p><strong>• EDGE_ENHANCE_MORE</strong>：边界增强滤波（程度更深）</p>
<p><strong>• EMBOSS</strong>：浮雕滤波</p>
<p><strong>• FIND_EDGES</strong>：寻找边界滤波</p>
<p><strong>• SMOOTH</strong>：平滑滤波</p>
<p><strong>• SMOOTH_MORE</strong>：平滑滤波（程度更深）</p>
<p><strong>• SHARPEN</strong>：锐化滤波</p>
<p><strong>• GaussianBlur(radius=2)</strong>：高斯模糊</p>
<p>​	&gt;radius指定平滑半径。</p>
<p><strong>• UnsharpMask(radius=2, percent=150, threshold=3)</strong>：反锐化掩码滤波</p>
<p>​	&gt;radius指定模糊半径；</p>
<p>​	&gt;percent指定反锐化强度（百分比）;</p>
<p>​	&gt;threshold控制被锐化的最小亮度变化。</p>
<p><strong>• Kernel(size, kernel, scale=None, offset=0)</strong>：核滤波</p>
<p>​	当前版本只支持核大小为3x3和5x5的核大小，且图像格式为“L”和“RGB”的图像。</p>
<p>​	&gt;size指定核大小（width, height）；</p>
<p>​	&gt;kernel指定核权值的序列；</p>
<p>​	&gt;scale指定缩放因子；</p>
<p>​	&gt;offset指定偏移量，如果使用，则将该值加到缩放后的结果上。</p>
<p><strong>• RankFilter(size, rank)</strong>：排序滤波</p>
<p>​	&gt;size指定滤波核的大小；</p>
<p>​	&gt;rank指定选取排在第rank位的像素，若大小为0，则为最小值滤波；若大小为size * size / 2则为中值滤波；若大小为size * size - 1则为最大值滤波。</p>
<p><strong>• MedianFilter(size=3)</strong>：中值滤波</p>
<p>​	&gt;size指定核的大小</p>
<p><strong>• MinFilter(size=3)</strong>：最小值滤波器</p>
<p>​	&gt;size指定核的大小</p>
<p><strong>•</strong> <strong>MaxFilter(size=3)</strong>：最大值滤波器</p>
<p>​	&gt;size指定核的大小</p>
<p><strong>•</strong> ModeFilter(size=3)**：波形滤波器</p>
<p>​	选取核内出现频次最高的像素值作为该点像素值，仅出现一次或两次的像素将被忽略，若没有像素出现两次以上，则保留原像素值。</p>
<p>​	&gt;size指定核的大小</p>
</blockquote>
<p>一段简单的代码可以测试两个滤波器：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> ImageFilter</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line">im = Image.open(<span class="string">&quot;test.png&quot;</span>)</span><br><span class="line">im_blur = im.filter(ImageFilter.GaussianBlur(radius=<span class="number">5</span>)) <span class="comment"># *高斯模糊</span></span><br><span class="line">im_contour = im.filter(ImageFilter.CONTOUR) <span class="comment"># *轮廓滤波</span></span><br><span class="line">im.show()</span><br><span class="line">im_blur.show()</span><br><span class="line">im_contour.show()</span><br></pre></td></tr></table></figure>
<p>可以看到不同滤波器带来的不同的改变：</p>
<blockquote>
<p><img src= "/img/loading.gif" data-lazy-src="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201014133724.png" alt="原图" style="zoom: 25%;" /><img src= "/img/loading.gif" data-lazy-src="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201014133359.png" alt="高斯模糊" style="zoom: 25%;" /><img src= "/img/loading.gif" data-lazy-src="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201014133834.png" alt="轮廓滤波" style="zoom: 25%;" /></p>
</blockquote>
<h3 id="3自己实现卷积滤波器"><a class="markdownIt-Anchor" href="#3自己实现卷积滤波器"></a> 3.自己实现卷积滤波器</h3>
<h4 id="1伟大的第一步确定算法基本思路"><a class="markdownIt-Anchor" href="#1伟大的第一步确定算法基本思路"></a> 1.伟大的第一步，确定算法基本思路</h4>
<ol>
<li><strong>初始化设置卷积核</strong></li>
<li><strong>读取图像二维列表形式存储的像素值</strong></li>
<li><strong>执行遍历获取新的像素值并存储到新的列表中</strong></li>
</ol>
<h4 id="2尝试实现"><a class="markdownIt-Anchor" href="#2尝试实现"></a> 2.尝试实现</h4>
<p>初始化设置卷积核：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">core = np.array([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">               [<span class="number">1</span>, <span class="number">1</span>, <span class="number">-1</span>],</span><br><span class="line">               [<span class="number">0</span>, <span class="number">-1</span>, <span class="number">-1</span>]])  <span class="comment"># *预设值的卷积核</span></span><br></pre></td></tr></table></figure>
<p>读取图像二维列表形式存储的像素值，并分离三通道：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">img = plt.imread(<span class="string">&quot;t1.jpg&quot;</span>)</span><br><span class="line">core_line = core.shape[<span class="number">0</span>] // <span class="number">2</span>  <span class="comment"># *获取卷积核行数</span></span><br><span class="line">core_row = core.shape[<span class="number">1</span>] // <span class="number">2</span>  <span class="comment"># *获取卷积核列数</span></span><br><span class="line"><span class="comment"># *分别在行前后添加i行,在列前后添加j列,第三维不填充,填充值为0(不会影响原图像)</span></span><br><span class="line">img = np.pad(img, ((core_line, core_line), (core_row, core_row), (<span class="number">0</span>, <span class="number">0</span>)), <span class="string">&#x27;constant&#x27;</span>)</span><br><span class="line">channel_r = img[:, :, <span class="number">0</span>]  <span class="comment"># *R通道像素值</span></span><br><span class="line">channel_g = img[:, :, <span class="number">1</span>]  <span class="comment"># *G通道像素值</span></span><br><span class="line">channel_b = img[:, :, <span class="number">2</span>]  <span class="comment"># *B通道像素值</span></span><br></pre></td></tr></table></figure>
<p>执行遍历获取新的像素值并存储到新的列表中：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calculate</span>(<span class="params">img, core</span>):</span></span><br><span class="line">    result = (img * core).sum()  <span class="comment"># *矩阵乘法获得结果像素值</span></span><br><span class="line">    <span class="keyword">if</span>(result &lt; <span class="number">0</span>):  <span class="comment"># *过滤无效像素值</span></span><br><span class="line">        result = <span class="number">0</span></span><br><span class="line">    <span class="keyword">elif</span> result &gt; <span class="number">255</span>:</span><br><span class="line">        result = <span class="number">255</span></span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line">channel_line = img.shape[<span class="number">0</span>] - core_line + <span class="number">1</span>  <span class="comment"># *获取图像像素点列数</span></span><br><span class="line">channel_row = img.shape[<span class="number">1</span>] - core_row + <span class="number">1</span>  <span class="comment"># *获取图像像素点行数</span></span><br><span class="line"></span><br><span class="line">new_img = np.zeros((channel_line, channel_row),</span><br><span class="line">                   dtype=<span class="string">&#x27;uint8&#x27;</span>)  <span class="comment"># *初始化一个和原图像大小相同的用0填充的图像矩阵</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> trange(channel_line):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(channel_row):</span><br><span class="line">        <span class="comment"># *调用calculate函数完成每个像素点的滤波计算并赋值给新图像</span></span><br><span class="line">        new_img[i][j] = calculate(img[i:i+core_line, j:j+core_row], core)</span><br></pre></td></tr></table></figure>
<p>最后把三通道合并，将函数分块获得最终代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pylab</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> trange</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">collect_channel</span>(<span class="params">img, core</span>):</span></span><br><span class="line">    core_line = core.shape[<span class="number">0</span>] // <span class="number">2</span>  <span class="comment"># *获取卷积核行数</span></span><br><span class="line">    core_row = core.shape[<span class="number">1</span>] // <span class="number">2</span>  <span class="comment"># *获取卷积核列数</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># *分别在行前后添加i行,在列前后添加j列,第三维不填充,填充值为0(不会影响原图像)</span></span><br><span class="line">    img = np.pad(img, ((core_line, core_line), (core_row, core_row), (<span class="number">0</span>, <span class="number">0</span>)), <span class="string">&#x27;constant&#x27;</span>)</span><br><span class="line">    channel_r = convolution(img[:, :, <span class="number">0</span>], core)  <span class="comment"># *提取R通道数据并执行卷积</span></span><br><span class="line">    channel_g = convolution(img[:, :, <span class="number">1</span>], core)  <span class="comment"># *提取G通道数据并执行卷积</span></span><br><span class="line">    channel_b = convolution(img[:, :, <span class="number">2</span>], core)  <span class="comment"># *提取B通道数据并执行卷积</span></span><br><span class="line"></span><br><span class="line">    dstack = np.dstack([channel_r, channel_g, channel_b])</span><br><span class="line">    <span class="keyword">return</span> dstack     <span class="comment"># *合并三个颜色通道</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convolution</span>(<span class="params">img, core</span>):</span></span><br><span class="line"></span><br><span class="line">    core_line = core.shape[<span class="number">0</span>]  <span class="comment"># *获取卷积核行数</span></span><br><span class="line">    core_row = core.shape[<span class="number">1</span>]  <span class="comment"># *获取卷积核列数</span></span><br><span class="line"></span><br><span class="line">    channel_line = img.shape[<span class="number">0</span>] - core_line + <span class="number">1</span>  <span class="comment"># *获取图像像素点列数</span></span><br><span class="line">    channel_row = img.shape[<span class="number">1</span>] - core_row + <span class="number">1</span>  <span class="comment"># *获取图像像素点行数</span></span><br><span class="line"></span><br><span class="line">    new_img = np.zeros((channel_line, channel_row),</span><br><span class="line">                       dtype=<span class="string">&#x27;uint8&#x27;</span>)  <span class="comment"># *初始化一个和原图像大小相同的用0填充的图像矩阵</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> trange(channel_line):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(channel_row):</span><br><span class="line">            <span class="comment"># *调用calculate函数完成每个像素点的滤波计算并赋值给新图像</span></span><br><span class="line">            new_img[i][j] = calculate(img[i:i+core_line, j:j+core_row], core)</span><br><span class="line">    <span class="keyword">return</span> new_img</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calculate</span>(<span class="params">img, core</span>):</span></span><br><span class="line">    result = (img * core).sum()  <span class="comment"># *矩阵乘法获得结果像素值</span></span><br><span class="line">    <span class="keyword">if</span>(result &lt; <span class="number">0</span>):  <span class="comment"># *过滤无效像素值</span></span><br><span class="line">        result = <span class="number">0</span></span><br><span class="line">    <span class="keyword">elif</span> result &gt; <span class="number">255</span>:</span><br><span class="line">        result = <span class="number">255</span></span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">img = plt.imread(<span class="string">&quot;t1.jpg&quot;</span>)</span><br><span class="line"></span><br><span class="line">core = np.array([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">               [<span class="number">1</span>, <span class="number">1</span>, <span class="number">-1</span>],</span><br><span class="line">               [<span class="number">0</span>, <span class="number">-1</span>, <span class="number">-1</span>]])  <span class="comment"># *预设的卷积核</span></span><br><span class="line"></span><br><span class="line">result = collect_channel(img, core)</span><br><span class="line">plt.imshow(result)</span><br><span class="line">plt.imsave(<span class="string">&quot;D:/0aJotang/#6/results.jpg&quot;</span>, result)</span><br><span class="line">pylab.show()</span><br></pre></td></tr></table></figure>
<p>对一个憨憨表情包处理后的结果如下：</p>
<p><img src= "/img/loading.gif" data-lazy-src="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201015163709.jpg" alt="原图" style="zoom:150%;" /><img src= "/img/loading.gif" data-lazy-src="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201015163919.jpg" alt="[1, 1, 0],[1, 0, -1],[0, -1, -1]" style="zoom:150%;" /><img src= "/img/loading.gif" data-lazy-src="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201015164304.jpg" alt="[1, 1, 0],[1, 0, 1],[0, 1, -1]" style="zoom:150%;" /><img src= "/img/loading.gif" data-lazy-src="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201015164002.jpg" alt="[1, 5, 0],[1, 0, -1],[0, -1, -1]" style="zoom:150%;" /></p>
<h4 id="3均值模糊高斯模糊"><a class="markdownIt-Anchor" href="#3均值模糊高斯模糊"></a> 3.均值模糊/高斯模糊</h4>
<p>要使用滤镜达到模糊的效果，我们可以理解为“图像细节的丢失”，但这种丢失不是简单的丢失了像素点，而是像素点和附近像素点的像素值差降低了，也就是更加“平滑”了，这一点和前面提到的“低通滤波器”比较类似。</p>
<p>要降低像素差值，我们可以对每个像素取附近像素点的平均值，这样每个像素值之间的差值就相应减少了。</p>
<ul>
<li>
<p><strong>均值模糊</strong></p>
<p>​	直接在卷积遍历过程中求整个矩阵的平均值并赋值给对应像素点：</p>
<p><code>修改求和函数即可做到</code></p>
<div class="note default icon flat"><p><strong>效果如图:</strong></p>
</div>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calculate</span>(<span class="params">img, core</span>):</span></span><br><span class="line">    result = (img * core).sum() / <span class="number">9</span>  <span class="comment"># *矩阵乘法获得结果像素值并求平均值</span></span><br><span class="line">    <span class="keyword">if</span>(result &lt; <span class="number">0</span>):  <span class="comment"># *过滤无效像素值</span></span><br><span class="line">        result = <span class="number">0</span></span><br><span class="line">    <span class="keyword">elif</span> result &gt; <span class="number">255</span>:</span><br><span class="line">        result = <span class="number">255</span></span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<p>效果举例：</p>
<p><img src= "/img/loading.gif" data-lazy-src="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201015195410.jpg" alt="原图" style="zoom: 50%;" /><img src= "/img/loading.gif" data-lazy-src="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201015195841.jpg" alt="3*3平均值卷积内核" style="zoom: 50%;" /><img src= "/img/loading.gif" data-lazy-src="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201015195443.jpg" alt="5*7平均值卷积内核" style="zoom: 50%;" /></p>
</li>
<li>
<p>高斯模糊</p>
<p>​	因为图像像素点分布实际上不是简单分布，每个像素点附近的像素点存在一定的连续性，距离越远，连续性就越不明显，这样的分布特点和正态分布一致，于是有使用正态分布(高斯函数)的方式来模糊处理图像的算法，这样的模糊方法因为过渡更加符合现实情况，在实拍的图片中使用效果会显得更加真实。</p>
<p>​	因为是二维的图像，所以需要使用到二维高斯函数：</p>
</li>
</ul>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>2</mn><msup><mrow><mi>π</mi><mi>σ</mi></mrow><mn>2</mn></msup></mrow></mfrac><msup><mi>e</mi><mfrac><msup><mrow></mrow><mrow><mo>−</mo><mo stretchy="false">(</mo><msup><mi>x</mi><mn>2</mn></msup><mo>+</mo><msup><mi>y</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow></msup><mrow><mn>2</mn><msup><mi>σ</mi><mn>2</mn></msup></mrow></mfrac></msup></mrow><annotation encoding="application/x-tex">G(x,y)=\frac1{2\mathrm{πσ}^2}e^\frac{ { }^{-(x^2+y^2)} } {2\sigma^2}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">G</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.13444em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.740108em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord">1</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.44844em;"><span style="top:-3.4534200000000004em;margin-right:0.05em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4214571428571432em;"><span style="top:-2.5436428571428573em;"><span class="pstrut" style="height:3.037457142857143em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9384399999999999em;"><span style="top:-2.93844em;margin-right:0.1em;"><span class="pstrut" style="height:2.64444em;"></span><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-3.262957142857143em;"><span class="pstrut" style="height:3.037457142857143em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.4214571428571428em;"><span class="pstrut" style="height:3.037457142857143em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mtight"></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.4524400000000002em;"><span style="top:-3.45244em;margin-right:0.1em;"><span class="pstrut" style="height:3.0484400000000003em;"></span><span class="mord mtight"><span class="mord mtight">−</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.04844em;"><span style="top:-3.04844em;margin-right:0.1em;"><span class="pstrut" style="height:2.64444em;"></span><span class="mord mtight">2</span></span></span></span></span></span></span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.04844em;"><span style="top:-3.04844em;margin-right:0.1em;"><span class="pstrut" style="height:2.64444em;"></span><span class="mord mtight">2</span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.49381428571428565em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<blockquote>
<p>​	其中，<strong>σ为模糊量</strong>，因为在正态分布中<strong>σ为方差</strong>，其值越大曲线越扁平，相应的模糊过渡越平滑，所以模糊量越大</p>
<p>​	此外，卷积核的半径与模糊程度也呈现<strong>正相关关系</strong></p>
</blockquote>
<p>实现起来也并不难，只需要计算出高斯函数的值并转化sum(core)=1就完成了：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib.pyplot <span class="keyword">import</span> pause</span><br><span class="line"><span class="keyword">import</span> pylab</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> trange</span><br><span class="line"></span><br><span class="line"><span class="comment"># *设置全局变量</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">public</span>():</span></span><br><span class="line">    <span class="keyword">global</span> core_line, core_row, sigma</span><br><span class="line">    core_line = <span class="number">10</span></span><br><span class="line">    core_row = <span class="number">10</span></span><br><span class="line">    sigma = <span class="number">5</span></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="comment"># *计算二维高斯函数值</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gaussian</span>(<span class="params">sigma, x, y</span>):</span></span><br><span class="line">    z = <span class="number">1</span>/(<span class="number">2</span> * np.pi * (sigma**<span class="number">2</span>)) * np.exp(-(x**<span class="number">2</span>+y**<span class="number">2</span>)/(<span class="number">2</span> * sigma**<span class="number">2</span>))</span><br><span class="line">    <span class="keyword">return</span> z</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">collect_channel</span>(<span class="params">img, core</span>):</span></span><br><span class="line">    public()</span><br><span class="line">    <span class="comment"># *分别在行前后添加i行,在列前后添加j列,第三维不填充,填充值为0(不会影响原图像)</span></span><br><span class="line">    img = np.pad(img, ((core_line, core_line),</span><br><span class="line">                       (core_row, core_row), (<span class="number">0</span>, <span class="number">0</span>)), <span class="string">&#x27;constant&#x27;</span>)</span><br><span class="line">    channel_r = convolution(img[:, :, <span class="number">0</span>], core)  <span class="comment"># *提取R通道数据并执行卷积</span></span><br><span class="line">    channel_g = convolution(img[:, :, <span class="number">1</span>], core)  <span class="comment"># *提取G通道数据并执行卷积</span></span><br><span class="line">    channel_b = convolution(img[:, :, <span class="number">2</span>], core)  <span class="comment"># *提取B通道数据并执行卷积</span></span><br><span class="line"></span><br><span class="line">    dstack = np.dstack([channel_r, channel_g, channel_b])</span><br><span class="line">    <span class="keyword">return</span> dstack     <span class="comment"># *合并三个颜色通道</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convolution</span>(<span class="params">img, core</span>):</span></span><br><span class="line">    public()</span><br><span class="line"></span><br><span class="line">    channel_line = img.shape[<span class="number">0</span>] - core_line + <span class="number">1</span>  <span class="comment"># *获取图像像素点列数</span></span><br><span class="line">    channel_row = img.shape[<span class="number">1</span>] - core_row + <span class="number">1</span>  <span class="comment"># *获取图像像素点行数</span></span><br><span class="line"></span><br><span class="line">    new_img = np.zeros((channel_line, channel_row),</span><br><span class="line">                       dtype=<span class="string">&#x27;uint8&#x27;</span>)  <span class="comment"># *初始化一个和原图像大小相同的用0填充的图像矩阵</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> trange(channel_line):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(channel_row):</span><br><span class="line">            <span class="comment"># *调用calculate函数完成每个像素点的滤波计算并赋值给新图像</span></span><br><span class="line">            new_img[i][j] = calculate(img[i:i+core_line, j:j+core_row], core)</span><br><span class="line">    <span class="keyword">return</span> new_img</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calculate</span>(<span class="params">img, core</span>):</span></span><br><span class="line"></span><br><span class="line">    result = (img * core).sum()  <span class="comment"># *矩阵乘法获得结果像素值</span></span><br><span class="line">    <span class="keyword">if</span>(result &lt; <span class="number">0</span>):  <span class="comment"># *过滤无效像素值</span></span><br><span class="line">        result = <span class="number">0</span></span><br><span class="line">    <span class="keyword">elif</span> result &gt; <span class="number">255</span>:</span><br><span class="line">        result = <span class="number">255</span></span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gaussian_cal</span>():</span></span><br><span class="line">    public()</span><br><span class="line">    <span class="comment"># *初始化卷积核</span></span><br><span class="line">    core = [[<span class="number">1.0</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(core_line)] <span class="keyword">for</span> j <span class="keyword">in</span> range(core_row)]</span><br><span class="line">    sums = <span class="number">0</span></span><br><span class="line">    <span class="comment"># *计算卷积核半径</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(core_line):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(core_row):</span><br><span class="line">            x = abs(j - (core_row // <span class="number">2</span>))</span><br><span class="line">            y = abs(i - (core_line // <span class="number">2</span>))</span><br><span class="line">            core[i][j] = gaussian(sigma, x, y)</span><br><span class="line">            sums = sums + core[i][j]</span><br><span class="line">    core = core / sums  <span class="comment"># *保证卷积核元素总和为1</span></span><br><span class="line">    <span class="keyword">return</span> core</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">img = plt.imread(<span class="string">&quot;D:/0aJotang/#6/nice.jpg&quot;</span>)</span><br><span class="line">plt.imshow(img)</span><br><span class="line">result = collect_channel(img, gaussian_cal())</span><br><span class="line">plt.imshow(result)</span><br><span class="line">plt.imsave(<span class="string">&quot;D:/0aJotang/#6/results1.jpg&quot;</span>, result)</span><br><span class="line">pylab.show()</span><br></pre></td></tr></table></figure>
<div class="note default icon flat"><p><strong>效果如图:</strong></p>
</div>
<p><img src= "/img/loading.gif" data-lazy-src="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201015195410.jpg" alt="原图" style="zoom: 50%;" /><img src= "/img/loading.gif" data-lazy-src="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201016002018.jpg" alt="sigma=5,core:5*5" style="zoom:50%;" /><img src= "/img/loading.gif" data-lazy-src="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201016002348.jpg" alt="sigma:20 core:15*15" style="zoom:50%;" /></p>
<h4 id="4其他滤镜"><a class="markdownIt-Anchor" href="#4其他滤镜"></a> 4.其他滤镜</h4>
<p>锐化类滤镜：主要通过强化中心像素值(即赋予高权重)的方式来增强边缘区域的特征</p>
<ul>
<li>
<p>浮雕滤镜</p>
<p><img src= "/img/loading.gif" data-lazy-src="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201016004730.jpg" alt="原图" style="zoom: 67%;" /><img src= "/img/loading.gif" data-lazy-src="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201016004747.jpg" alt="浮雕效果" style="zoom: 67%;" /></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mtable rowspacing="0.15999999999999992em" columnalign="center center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>1</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{array} {ccc}-1&amp;0&amp;0\\0&amp;1&amp;0\\0&amp;0&amp;0\end{array}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.6000000000000005em;vertical-align:-1.5500000000000007em;"></span><span class="mord"><span class="mtable"><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord">1</span></span></span><span style="top:-3.0099999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-1.8099999999999994em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5500000000000007em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-3.0099999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span><span style="top:-1.8099999999999994em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5500000000000007em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-3.0099999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-1.8099999999999994em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5500000000000007em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span></span></span></span></span></span></span></p>
</li>
<li>
<p>轮廓提取</p>
<p><img src= "/img/loading.gif" data-lazy-src="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201016004730.jpg" alt="原图" style="zoom: 67%;" /><img src= "/img/loading.gif" data-lazy-src="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201016005057.jpg" alt="轮廓提取" style="zoom:67%;" /></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mtable rowspacing="0.15999999999999992em" columnalign="center center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>1</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>1</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>1</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>1</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>8</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>1</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>1</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>1</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mn>1</mn></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{array} {ccc}-1&amp;-1&amp;-1\\-1&amp;8&amp;-1\\-1&amp;-1&amp;-1\end{array}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.6000000000000005em;vertical-align:-1.5500000000000007em;"></span><span class="mord"><span class="mtable"><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord">1</span></span></span><span style="top:-3.0099999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord">1</span></span></span><span style="top:-1.8099999999999994em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5500000000000007em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord">1</span></span></span><span style="top:-3.0099999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">8</span></span></span><span style="top:-1.8099999999999994em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5500000000000007em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord">1</span></span></span><span style="top:-3.0099999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord">1</span></span></span><span style="top:-1.8099999999999994em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5500000000000007em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span></span></span></span></span></span></span></p>
</li>
<li>
<p>更多滤镜，魔改卷积核······</p>
</li>
</ul>
<h2 id="任务二"><a class="markdownIt-Anchor" href="#任务二"></a> 任务二</h2>
<h3 id="1认识图片风格迁移"><a class="markdownIt-Anchor" href="#1认识图片风格迁移"></a> 1.认识图片风格迁移</h3>
<p><strong>所谓图片风格迁移，是指利用程序算法学习特定图片的风格，然后再把这种风格应用到另外一张图片上的技术。</strong></p>
<p>传统的方法是分析某类风格的图像，对其图像特征进行建模，再通过这个模型来应用到目标图像上，缺点是只能针对每一类图像单独建模，而且不同风格的图像建模的方法差异也很大：</p>
<img src= "/img/loading.gif" data-lazy-src="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201016123905.jpeg" alt="传统风格迁移" style="zoom: 67%;" />
<p>后来出现了基于神经网络学习的风格迁移算法，让程序使用任意一张图片的风格进行风格迁移成为可能：</p>
<img src= "/img/loading.gif" data-lazy-src="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201016123834.jpeg" alt="神经网络风格迁移算法" style="zoom:50%;" />
<p>基于神经网络的风格迁移算法，大致可以描述为：</p>
<blockquote>
<p>定义两个表示距离的变量,一个表示输入图片和内容图片的距离(Dc),一个表示输入图片和样式图片的距离(Ds).即Dc测量输入和内容图片的内容差异的距离,Ds则测量输入和样式图片之间样式的差异距离.优化Dc和Ds使之最小,即完成图像风格转移</p>
</blockquote>
<h3 id="2使用pytorch实现图片风格迁移"><a class="markdownIt-Anchor" href="#2使用pytorch实现图片风格迁移"></a> 2.使用pytorch实现图片风格迁移</h3>
<h4 id="1核心思想"><a class="markdownIt-Anchor" href="#1核心思想"></a> 1.核心思想</h4>
<blockquote>
<p>使用CNN(卷积神经网络)提取内容图片的内容和风格图片的风格，然后将这两项特征输入到一张新的图像中。对输入的图像提取出内容和风格与CNN提取的内容和风格进行Loss计算，用MSE度量，然后逐步对Loss进行优化，使Loss值达到最理想，将被优化的参数进行输出，这样输出的图片就达到了风格迁移的目的。</p>
</blockquote>
<ul>
<li>计算风格损失和内容损失，并逐步降低梯度优化损失，最后优化参数输出</li>
<li>通过预训练的卷积网络提取出更高纬度的图片内容和风格，最后通过定义内容损失函数和风格损失函数进行反向传播更新参数</li>
</ul>
<h4 id="2功能分步实现"><a class="markdownIt-Anchor" href="#2功能分步实现"></a> 2.功能分步实现</h4>
<h5 id="1加载图片"><a class="markdownIt-Anchor" href="#1加载图片"></a> 1.加载图片</h5>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># *输出图像大小</span></span><br><span class="line">imsize = <span class="number">512</span></span><br><span class="line">loader = transforms.Compose([</span><br><span class="line">    transforms.Resize(imsize),  <span class="comment"># *拉伸调整输入图像尺寸</span></span><br><span class="line">    transforms.ToTensor()])  <span class="comment"># *将图像转换为torch张量</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># *图像载入</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">image_loader</span>(<span class="params">image_name</span>):</span></span><br><span class="line">    image = Image.open(image_name)</span><br><span class="line">    image = loader(image).unsqueeze(<span class="number">0</span>) <span class="comment"># *添加伪维数以满足神经网络要求的输入维数</span></span><br><span class="line">    <span class="keyword">return</span> image.to(device, torch.float)</span><br><span class="line"></span><br><span class="line"><span class="comment"># *转换并绘制图像</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">imshow</span>(<span class="params">tensor, title=None</span>):</span></span><br><span class="line">    unloader = transforms.ToPILImage() </span><br><span class="line">    image = tensor.cpu().clone()  <span class="comment"># *clone张量</span></span><br><span class="line">    image = image.squeeze(<span class="number">0</span>)      <span class="comment"># *移除添加的伪维</span></span><br><span class="line">    image = unloader(image)  <span class="comment"># *转换回PIL图像</span></span><br><span class="line">    plt.imshow(image)  <span class="comment"># *绘制图像</span></span><br><span class="line">    <span class="keyword">if</span> title <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        plt.title(title)</span><br><span class="line">    plt.pause(<span class="number">0.001</span>)  <span class="comment"># *暂停使plot子图更新</span></span><br></pre></td></tr></table></figure>
<h5 id="2计算损失"><a class="markdownIt-Anchor" href="#2计算损失"></a> 2.计算损失</h5>
<ol>
<li>
<p>内容损失</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi></mrow></msub><mrow><mo fence="true">(</mo><mover><mo><mi>p</mi></mo><mo>⇀</mo></mover><mo separator="true">,</mo><mover><mo><mi>x</mi></mo><mo>⇀</mo></mover><mo separator="true">,</mo><mi>l</mi><mo fence="true">)</mo></mrow><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><munder><mo>∑</mo><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></munder><msup><mrow><mo stretchy="false">(</mo><msubsup><mi>F</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow><mi>l</mi></msubsup><mo>−</mo><msubsup><mi>P</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow><mi>l</mi></msubsup><mo stretchy="false">)</mo></mrow><mn>2</mn></msup><mspace linebreak="newline"></mspace></mrow><annotation encoding="application/x-tex">L_{content}\left(\overset\rightharpoonup p,\overset\rightharpoonup x,l\right)=\frac12\sum_{i,j} {(F_{i,j}^l-P_{i,j}^l)}^2\\
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.80002em;vertical-align:-0.65002em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">n</span><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">n</span><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9873689999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop mathdefault">p</span></span></span><span style="top:-3.63056em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mrel mtight">⇀</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mop op-limits"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9873689999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop mathdefault">x</span></span></span><span style="top:-3.63056em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mrel mtight">⇀</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">)</span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.735217em;vertical-align:-1.413777em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord">2</span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord">1</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.8723309999999997em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.413777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord"><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.899108em;"><span style="top:-2.4530000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.899108em;"><span style="top:-2.4530000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.103116em;"><span style="top:-3.352008em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mspace newline"></span></span></span></span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># *内容损失</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ContentLoss</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, target,</span>):</span></span><br><span class="line">        super(ContentLoss, self).__init__()</span><br><span class="line">        self.target = target.detach()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, input</span>):</span></span><br><span class="line">        self.loss = F.mse_loss(input, self.target)  <span class="comment"># *调用mse_loss计算矩阵均方损失</span></span><br><span class="line">        <span class="keyword">return</span> input</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li>
<p>风格损失</p>
<p>style loss取自原始image和生成的image在神经网络中的Gram matrix的MSE(Gram矩阵可以在一定程度上反映原始图像的“风格”):</p>
<p><img src= "/img/loading.gif" data-lazy-src="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201018013104.webp" alt="img" /></p>
<p><code>因为公式字母太多写LaTex太麻烦于是就用了图片XD</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># *计算Gram矩阵</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gram_matrix</span>(<span class="params">input</span>):</span></span><br><span class="line">    a, b, c, d = input.size()  <span class="comment"># a=batch size(=1)</span></span><br><span class="line">    <span class="comment"># *特征映射 b=number</span></span><br><span class="line">    <span class="comment"># *(c,d)=dimensions of a f. map (N=c*d)</span></span><br><span class="line"></span><br><span class="line">    features = input.view(a * b, c * d)  <span class="comment"># *将矩阵F_XL重塑为\hat F_XL</span></span><br><span class="line"></span><br><span class="line">    G = torch.mm(features, features.t())  <span class="comment"># *计算gram积</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># *归一化gram矩阵的值.</span></span><br><span class="line">    <span class="keyword">return</span> G.div(a * b * c * d)</span><br><span class="line"></span><br><span class="line"><span class="comment"># *风格损失计算(与内容损失计算类似)</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StyleLoss</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, target_feature</span>):</span></span><br><span class="line">        super(StyleLoss, self).__init__()</span><br><span class="line">        self.target = gram_matrix(target_feature).detach()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, input</span>):</span></span><br><span class="line">        G = gram_matrix(input)</span><br><span class="line">        self.loss = F.mse_loss(G, self.target)</span><br><span class="line">        <span class="keyword">return</span> input</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h5 id="3降低梯度"><a class="markdownIt-Anchor" href="#3降低梯度"></a> 3.降低梯度</h5>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_input_optimizer</span>(<span class="params">input_img</span>):</span></span><br><span class="line">    optimizer = optim.LBFGS([input_img.requires_grad_()])</span><br><span class="line">    <span class="keyword">return</span> optimizer</span><br></pre></td></tr></table></figure>
<h5 id="4规范化输入图像以导入nnsequential"><a class="markdownIt-Anchor" href="#4规范化输入图像以导入nnsequential"></a> 4.规范化输入图像以导入nn.Sequential</h5>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Normalization</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, mean, std</span>):</span></span><br><span class="line">        super(Normalization, self).__init__()</span><br><span class="line">        <span class="comment"># *计算均值、均方差以归一化矩阵</span></span><br><span class="line">        self.mean = torch.tensor(mean).view(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        self.std = torch.tensor(std).view(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, img</span>):</span></span><br><span class="line">        <span class="comment"># *归一化矩阵</span></span><br><span class="line">        <span class="keyword">return</span> (img - self.mean) / self.std</span><br></pre></td></tr></table></figure>
<h5 id="5获得风格模型和损失量"><a class="markdownIt-Anchor" href="#5获得风格模型和损失量"></a> 5.获得风格模型和损失量</h5>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># *获得风格模型和损失量</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_style_model_and_losses</span>(<span class="params">cnn, normalization_mean, normalization_std,</span></span></span><br><span class="line"><span class="function"><span class="params">                               style_img, content_img,</span></span></span><br><span class="line"><span class="function"><span class="params">                               content_layers=content_layers_default,</span></span></span><br><span class="line"><span class="function"><span class="params">                               style_layers=style_layers_default</span>):</span></span><br><span class="line">    cnn = copy.deepcopy(cnn)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># *规范化模块</span></span><br><span class="line">    normalization = Normalization(</span><br><span class="line">        normalization_mean, normalization_std).to(device)</span><br><span class="line">    <span class="comment"># *只是为了拥有可迭代的访问权限或列出内容/系统损失</span></span><br><span class="line">    content_losses = []</span><br><span class="line">    style_losses = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># *创建一个新的nn.Sequential来放入按序激活的模块</span></span><br><span class="line">    model = nn.Sequential(normalization)</span><br><span class="line"></span><br><span class="line">    i = <span class="number">0</span>  <span class="comment"># *每次检视层的增量</span></span><br><span class="line">    <span class="keyword">for</span> layer <span class="keyword">in</span> cnn.children():</span><br><span class="line">        <span class="keyword">if</span> isinstance(layer, nn.Conv2d):</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">            name = <span class="string">&#x27;conv_&#123;&#125;&#x27;</span>.format(i)</span><br><span class="line">        <span class="keyword">elif</span> isinstance(layer, nn.ReLU):</span><br><span class="line">            name = <span class="string">&#x27;relu_&#123;&#125;&#x27;</span>.format(i)</span><br><span class="line">            <span class="comment"># *在下面插入的ContentLoss和StyleLoss的本地版本不能很好地发挥作用。所以在这里替换不合适的</span></span><br><span class="line">            layer = nn.ReLU(inplace=<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">elif</span> isinstance(layer, nn.MaxPool2d):</span><br><span class="line">            name = <span class="string">&#x27;pool_&#123;&#125;&#x27;</span>.format(i)</span><br><span class="line">        <span class="keyword">elif</span> isinstance(layer, nn.BatchNorm2d):</span><br><span class="line">            name = <span class="string">&#x27;bn_&#123;&#125;&#x27;</span>.format(i)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> RuntimeError(<span class="string">&#x27;Unrecognized layer: &#123;&#125;&#x27;</span>.format(</span><br><span class="line">                layer.__class__.__name__))</span><br><span class="line"></span><br><span class="line">        model.add_module(name, layer)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> name <span class="keyword">in</span> content_layers:</span><br><span class="line">            <span class="comment"># *加入内容损失:</span></span><br><span class="line">            target = model(content_img).detach()</span><br><span class="line">            content_loss = ContentLoss(target)</span><br><span class="line">            model.add_module(<span class="string">&quot;content_loss_&#123;&#125;&quot;</span>.format(i), content_loss)</span><br><span class="line">            content_losses.append(content_loss)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> name <span class="keyword">in</span> style_layers:</span><br><span class="line">            <span class="comment"># *加入风格损失:</span></span><br><span class="line">            target_feature = model(style_img).detach()</span><br><span class="line">            style_loss = StyleLoss(target_feature)</span><br><span class="line">            model.add_module(<span class="string">&quot;style_loss_&#123;&#125;&quot;</span>.format(i), style_loss)</span><br><span class="line">            style_losses.append(style_loss)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># *移除添加的损失层</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(model) - <span class="number">1</span>, <span class="number">-1</span>, <span class="number">-1</span>):</span><br><span class="line">        <span class="keyword">if</span> isinstance(model[i], ContentLoss) <span class="keyword">or</span> isinstance(model[i], StyleLoss):</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    model = model[:(i + <span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model, style_losses, content_losses</span><br></pre></td></tr></table></figure>
<h4 id="3完整示例代码"><a class="markdownIt-Anchor" href="#3完整示例代码"></a> 3.完整示例代码</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="comment"># *指定计算设备</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># *输出图像大小</span></span><br><span class="line">imsize = <span class="number">512</span></span><br><span class="line">loader = transforms.Compose([</span><br><span class="line">    transforms.Resize(imsize),  <span class="comment"># *拉伸调整输入图像尺寸</span></span><br><span class="line">    transforms.ToTensor()])  <span class="comment"># *将图像转换为torch张量</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># *图像载入</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">image_loader</span>(<span class="params">image_name</span>):</span></span><br><span class="line">    image = Image.open(image_name)</span><br><span class="line">    <span class="comment"># *添加伪维数以满足神经网络要求的输入维数</span></span><br><span class="line">    image = loader(image).unsqueeze(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> image.to(device, torch.float)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">style_img = image_loader(<span class="string">&quot;D:/0aJotang/#6/py_fi/input_style/style.jpg&quot;</span>)  <span class="comment"># *读取风格图像</span></span><br><span class="line">content_img = image_loader(<span class="string">&quot;D:/0aJotang/#6/py_fi/input_content/content.jpg&quot;</span>)  <span class="comment"># *读取内容图像</span></span><br><span class="line"><span class="comment"># *确认传入内容和风格图像尺寸一致</span></span><br><span class="line"><span class="keyword">assert</span> style_img.size() == content_img.size(), \</span><br><span class="line">    <span class="string">&quot;we need to import style and content images of the same size&quot;</span></span><br><span class="line"></span><br><span class="line">unloader = transforms.ToPILImage()  <span class="comment"># *将图像转换回PIL—image以在plot绘制</span></span><br><span class="line"></span><br><span class="line">plt.ion()</span><br><span class="line"></span><br><span class="line"><span class="comment"># *用于转换并绘制图像</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">imshow</span>(<span class="params">tensor, title=None</span>):</span></span><br><span class="line">    image = tensor.cpu().clone()  <span class="comment"># *clone张量</span></span><br><span class="line">    image = image.squeeze(<span class="number">0</span>)      <span class="comment"># *移除添加的伪维</span></span><br><span class="line">    image = unloader(image)  <span class="comment"># *重新转换回PIL图像</span></span><br><span class="line">    plt.imshow(image)  <span class="comment"># *绘制图像</span></span><br><span class="line">    <span class="keyword">if</span> title <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        plt.title(title)</span><br><span class="line">    plt.pause(<span class="number">0.001</span>)  <span class="comment"># *暂停使plot子图更新</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># *内容损失</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ContentLoss</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, target,</span>):</span></span><br><span class="line">        super(ContentLoss, self).__init__()</span><br><span class="line">        self.target = target.detach()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, input</span>):</span></span><br><span class="line">        self.loss = F.mse_loss(input, self.target)  <span class="comment"># *计算损失</span></span><br><span class="line">        <span class="keyword">return</span> input</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># *计算gram矩阵</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gram_matrix</span>(<span class="params">input</span>):</span></span><br><span class="line">    a, b, c, d = input.size()  <span class="comment"># a=batch size(=1)</span></span><br><span class="line">    <span class="comment"># *特征映射 b=number</span></span><br><span class="line">    <span class="comment"># *(c,d)=dimensions of a f. map (N=c*d)</span></span><br><span class="line"></span><br><span class="line">    features = input.view(a * b, c * d)  <span class="comment"># *将矩阵F_XL重塑为\hat F_XL</span></span><br><span class="line"></span><br><span class="line">    G = torch.mm(features, features.t())  <span class="comment"># *计算gram积</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># *归一化gram矩阵的值.</span></span><br><span class="line">    <span class="keyword">return</span> G.div(a * b * c * d)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># *风格损失计算</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StyleLoss</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, target_feature</span>):</span></span><br><span class="line">        super(StyleLoss, self).__init__()</span><br><span class="line">        self.target = gram_matrix(target_feature).detach()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, input</span>):</span></span><br><span class="line">        G = gram_matrix(input)</span><br><span class="line">        self.loss = F.mse_loss(G, self.target)</span><br><span class="line">        <span class="keyword">return</span> input</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># *导入预训练模型</span></span><br><span class="line">cnn = models.vgg19(pretrained=<span class="literal">True</span>).features.to(device).eval()</span><br><span class="line"></span><br><span class="line">cnn_normalization_mean = torch.tensor([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>]).to(device)</span><br><span class="line">cnn_normalization_std = torch.tensor([<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]).to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># *规范化输入图像以导入nn.Sequential</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Normalization</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, mean, std</span>):</span></span><br><span class="line">        super(Normalization, self).__init__()</span><br><span class="line">        <span class="comment"># *计算均值、均方差以归一化矩阵</span></span><br><span class="line">        self.mean = torch.tensor(mean).view(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        self.std = torch.tensor(std).view(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, img</span>):</span></span><br><span class="line">        <span class="comment"># *归一化矩阵</span></span><br><span class="line">        <span class="keyword">return</span> (img - self.mean) / self.std</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># *计算样式/内容损失的期望深度层：</span></span><br><span class="line">content_layers_default = [<span class="string">&#x27;conv_4&#x27;</span>]</span><br><span class="line">style_layers_default = [<span class="string">&#x27;conv_1&#x27;</span>, <span class="string">&#x27;conv_2&#x27;</span>, <span class="string">&#x27;conv_3&#x27;</span>, <span class="string">&#x27;conv_4&#x27;</span>, <span class="string">&#x27;conv_5&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># *获得风格模型和损失量</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_style_model_and_losses</span>(<span class="params">cnn, normalization_mean, normalization_std,</span></span></span><br><span class="line"><span class="function"><span class="params">                               style_img, content_img,</span></span></span><br><span class="line"><span class="function"><span class="params">                               content_layers=content_layers_default,</span></span></span><br><span class="line"><span class="function"><span class="params">                               style_layers=style_layers_default</span>):</span></span><br><span class="line">    cnn = copy.deepcopy(cnn)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># *规范化模块</span></span><br><span class="line">    normalization = Normalization(</span><br><span class="line">        normalization_mean, normalization_std).to(device)</span><br><span class="line">    <span class="comment"># *只是为了拥有可迭代的访问权限或列出内容/系统损失</span></span><br><span class="line">    content_losses = []</span><br><span class="line">    style_losses = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># *创建一个新的nn.Sequential来放入按序激活的模块</span></span><br><span class="line">    model = nn.Sequential(normalization)</span><br><span class="line"></span><br><span class="line">    i = <span class="number">0</span>  <span class="comment"># *每次检视层的增量</span></span><br><span class="line">    <span class="keyword">for</span> layer <span class="keyword">in</span> cnn.children():</span><br><span class="line">        <span class="keyword">if</span> isinstance(layer, nn.Conv2d):</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">            name = <span class="string">&#x27;conv_&#123;&#125;&#x27;</span>.format(i)</span><br><span class="line">        <span class="keyword">elif</span> isinstance(layer, nn.ReLU):</span><br><span class="line">            name = <span class="string">&#x27;relu_&#123;&#125;&#x27;</span>.format(i)</span><br><span class="line">            <span class="comment"># *对于我们在下面插入的ContentLoss和StyleLoss，</span></span><br><span class="line">            <span class="comment"># *本地版本不能很好地发挥作用。所以我们在这里替换不合适的</span></span><br><span class="line">            layer = nn.ReLU(inplace=<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">elif</span> isinstance(layer, nn.MaxPool2d):</span><br><span class="line">            name = <span class="string">&#x27;pool_&#123;&#125;&#x27;</span>.format(i)</span><br><span class="line">        <span class="keyword">elif</span> isinstance(layer, nn.BatchNorm2d):</span><br><span class="line">            name = <span class="string">&#x27;bn_&#123;&#125;&#x27;</span>.format(i)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> RuntimeError(<span class="string">&#x27;Unrecognized layer: &#123;&#125;&#x27;</span>.format(</span><br><span class="line">                layer.__class__.__name__))</span><br><span class="line"></span><br><span class="line">        model.add_module(name, layer)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> name <span class="keyword">in</span> content_layers:</span><br><span class="line">            <span class="comment"># *加入内容损失:</span></span><br><span class="line">            target = model(content_img).detach()</span><br><span class="line">            content_loss = ContentLoss(target)</span><br><span class="line">            model.add_module(<span class="string">&quot;content_loss_&#123;&#125;&quot;</span>.format(i), content_loss)</span><br><span class="line">            content_losses.append(content_loss)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> name <span class="keyword">in</span> style_layers:</span><br><span class="line">            <span class="comment"># *加入风格损失:</span></span><br><span class="line">            target_feature = model(style_img).detach()</span><br><span class="line">            style_loss = StyleLoss(target_feature)</span><br><span class="line">            model.add_module(<span class="string">&quot;style_loss_&#123;&#125;&quot;</span>.format(i), style_loss)</span><br><span class="line">            style_losses.append(style_loss)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># *移除添加的损失层</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(model) - <span class="number">1</span>, <span class="number">-1</span>, <span class="number">-1</span>):</span><br><span class="line">        <span class="keyword">if</span> isinstance(model[i], ContentLoss) <span class="keyword">or</span> isinstance(model[i], StyleLoss):</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    model = model[:(i + <span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model, style_losses, content_losses</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">input_img = content_img.clone()  <span class="comment"># *读取并clone内容图片</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># *降低梯度</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_input_optimizer</span>(<span class="params">input_img</span>):</span></span><br><span class="line">    optimizer = optim.LBFGS([input_img.requires_grad_()])</span><br><span class="line">    <span class="keyword">return</span> optimizer</span><br><span class="line"></span><br><span class="line"><span class="comment"># *运行风格迁移</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_style_transfer</span>(<span class="params">cnn, normalization_mean, normalization_std,</span></span></span><br><span class="line"><span class="function"><span class="params">                       content_img, style_img, input_img, num_steps=<span class="number">300</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                       style_weight=<span class="number">1000000</span>, content_weight=<span class="number">1</span></span>):</span></span><br><span class="line">    print(<span class="string">&#x27;Building the style transfer model..&#x27;</span>)</span><br><span class="line">    model, style_losses, content_losses = get_style_model_and_losses(cnn,</span><br><span class="line">                                                                     normalization_mean, normalization_std, style_img, content_img)</span><br><span class="line">    optimizer = get_input_optimizer(input_img)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">&#x27;Optimizing..&#x27;</span>)</span><br><span class="line">    run = [<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">while</span> run[<span class="number">0</span>] &lt;= num_steps:</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">closure</span>():</span></span><br><span class="line">            <span class="comment"># *修正更新的输入图像的值</span></span><br><span class="line">            input_img.data.clamp_(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            model(input_img)</span><br><span class="line">            style_score = <span class="number">0</span></span><br><span class="line">            content_score = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> sl <span class="keyword">in</span> style_losses:</span><br><span class="line">                style_score += sl.loss</span><br><span class="line">            <span class="keyword">for</span> cl <span class="keyword">in</span> content_losses:</span><br><span class="line">                content_score += cl.loss</span><br><span class="line"></span><br><span class="line">            style_score *= style_weight</span><br><span class="line">            content_score *= content_weight</span><br><span class="line"></span><br><span class="line">            loss = style_score + content_score</span><br><span class="line">            loss.backward()</span><br><span class="line"></span><br><span class="line">            run[<span class="number">0</span>] += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> run[<span class="number">0</span>] % <span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">                print(<span class="string">&quot;run &#123;&#125;:&quot;</span>.format(run))</span><br><span class="line">                print(<span class="string">&#x27;Style Loss : &#123;:4f&#125; Content Loss: &#123;:4f&#125;&#x27;</span>.format(</span><br><span class="line">                    style_score.item(), content_score.item()))</span><br><span class="line">                print()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> style_score + content_score</span><br><span class="line"></span><br><span class="line">        optimizer.step(closure)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># *修正张量为(0,1)</span></span><br><span class="line">    input_img.data.clamp_(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> input_img</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">output = run_style_transfer(cnn, cnn_normalization_mean, cnn_normalization_std,</span><br><span class="line">                            content_img, style_img, input_img)</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">imshow(output, title=<span class="string">&#x27;Output Image&#x27;</span>)</span><br><span class="line">plt.savefig(<span class="string">&quot;D:/0aJotang/#6/py_fi/output/output.png&quot;</span>)</span><br><span class="line">plt.ioff()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>输入图片效果示例：</p>
<p><img src= "/img/loading.gif" data-lazy-src="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201018020705.png" alt="风格图像" /><img src= "/img/loading.gif" data-lazy-src="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201018020731.png" alt="内容图像" /><img src= "/img/loading.gif" data-lazy-src="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201018020742.png" alt="输出图像" /></p>
<p><img src= "/img/loading.gif" data-lazy-src="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201018142208.png" alt="input_style" style="zoom: 50%;" /><img src= "/img/loading.gif" data-lazy-src="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201018142149.png" alt="input_content" style="zoom: 50%;" /><img src= "/img/loading.gif" data-lazy-src="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201018142219.png" alt="output" style="zoom: 50%;" /></p>
<p><img src= "/img/loading.gif" data-lazy-src="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201019110100.jpg" alt="style" style="zoom:67%;" /><img src= "/img/loading.gif" data-lazy-src="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201019110134.jpg" alt="content-2" style="zoom:67%;" /><img src= "/img/loading.gif" data-lazy-src="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201019110153.png" alt="output" style="zoom:67%;" /></p>
<h3 id="3快速风格迁移"><a class="markdownIt-Anchor" href="#3快速风格迁移"></a> 3.快速风格迁移</h3>
<h4 id="1什么是快速风格迁移"><a class="markdownIt-Anchor" href="#1什么是快速风格迁移"></a> 1.什么是快速风格迁移</h4>
<div class="note warning icon flat"><p>这一部分有可能要弃坑了，看的俺脑阔痛QAQ(其实是摸鱼之心突然崛起了)</p>
</div>
<footer style="text-align: center">
  <div>Copyright © 2020 Kevin Matt</div>
  <div>All Rights Reserved</div>
  <div>
    欢迎造访我的博客
    <a href="https://www.kevinmatt.top/" style="color: black" target="_blank"
      >Kevin's Space
    </a>
  </div>
  <div>
    焦糖工作室官网
    <a href="https://jotang.club/" style="color: black" target="_blank"
      >Jotang Studio</a
    >
  </div>
</footer></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:he_yuheng@163.com">Kevin Matt</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://heyuhengmatt.github.io/2020/10/1464568.html">https://heyuhengmatt.github.io/2020/10/1464568.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://heyuhengmatt.github.io" target="_blank">Kevin's Space</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/python/">python</a><a class="post-meta__tags" href="/tags/filter/">filter</a></div><div class="post_share"><div class="social-share" data-image="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201018143620.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://kevinmatt-1303917904.file.myqcloud.com/wechat_pay.png" target="_blank"><img class="post-qr-code-img" data-lazy-src="https://kevinmatt-1303917904.file.myqcloud.com/wechat_pay.png" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="https://kevinmatt-1303917904.file.myqcloud.com/ali_pay.png" target="_blank"><img class="post-qr-code-img" data-lazy-src="https://kevinmatt-1303917904.file.myqcloud.com/ali_pay.png" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2020/10/1765514.html"><img class="prev-cover" data-lazy-src="https://kevinmatt-1303917904.file.myqcloud.com/20201018022159.png" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">对流量明星的一通胡乱点评</div></div></a></div><div class="next-post pull-right"><a href="/2020/10/1357388.html"><img class="next-cover" data-lazy-src="https://www.z4a.net/images/2020/10/08/plswork-2.gif" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">使用python绘制传球事件和统计图像</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2020/10/1357388.html" title="使用python绘制传球事件和统计图像"><img class="cover" data-lazy-src="https://www.z4a.net/images/2020/10/08/plswork-2.gif" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-10-13</div><div class="title">使用python绘制传球事件和统计图像</div></div></a></div><div><a href="/2020/10/1827185.html" title="神经网络学习笔记"><img class="cover" data-lazy-src="https://kevinmatt-1303917904.file.myqcloud.com/20201021010348.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-10-18</div><div class="title">神经网络学习笔记</div></div></a></div><div><a href="/2020/10/1112993.html" title="利用python实现自动通过滑动验证码"><img class="cover" data-lazy-src="https://www.z4a.net/images/2020/10/08/slide_bkg.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-10-11</div><div class="title">利用python实现自动通过滑动验证码</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside_content" id="aside_content"><div class="card-widget card-info"><div class="card-content"><div class="card-info-avatar is-center"><img class="avatar-img" data-lazy-src="https://s1.ax1x.com/2020/10/11/067U1A.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">Kevin Matt</div><div class="author-info__description">摸鱼达人</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">17</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">24</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/heyuhengmatt"><i class="fab fa-github"></i><span>heyuhengmatt</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/heyuhengmatt" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:he_yuheng@163.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="card-content"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#python%E6%BB%A4%E9%95%9C%E5%92%8C%E5%9B%BE%E5%83%8F%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB"><span class="toc-number">1.</span> <span class="toc-text"> Python滤镜和图像风格迁移</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A1%E4%B8%80"><span class="toc-number">1.1.</span> <span class="toc-text"> 任务一</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E4%BA%86%E8%A7%A3%E6%BB%A4%E6%B3%A2%E5%99%A8"><span class="toc-number">1.1.1.</span> <span class="toc-text"> 1.了解滤波器</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%80-%E5%9B%BE%E5%83%8F%E6%9C%AC%E8%B4%A8%E4%B8%8A%E5%B0%B1%E6%98%AF%E5%90%84%E7%A7%8D%E8%89%B2%E5%BD%A9%E6%B3%A2%E7%9A%84%E5%8F%A0%E5%8A%A0"><span class="toc-number">1.1.1.1.</span> <span class="toc-text"> 一、图像本质上就是各种色彩波的叠加</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%8C-%E7%90%86%E8%A7%A3%E5%8D%B7%E7%A7%AF%E7%AE%97%E6%B3%95"><span class="toc-number">1.1.1.2.</span> <span class="toc-text"> 二、理解卷积算法</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E5%B0%9D%E8%AF%95%E4%BD%BF%E7%94%A8%E7%8E%B0%E6%88%90%E7%9A%84%E6%BB%A4%E6%B3%A2%E5%99%A8"><span class="toc-number">1.1.2.</span> <span class="toc-text"> 2.尝试使用现成的滤波器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%E8%87%AA%E5%B7%B1%E5%AE%9E%E7%8E%B0%E5%8D%B7%E7%A7%AF%E6%BB%A4%E6%B3%A2%E5%99%A8"><span class="toc-number">1.1.3.</span> <span class="toc-text"> 3.自己实现卷积滤波器</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1%E4%BC%9F%E5%A4%A7%E7%9A%84%E7%AC%AC%E4%B8%80%E6%AD%A5%E7%A1%AE%E5%AE%9A%E7%AE%97%E6%B3%95%E5%9F%BA%E6%9C%AC%E6%80%9D%E8%B7%AF"><span class="toc-number">1.1.3.1.</span> <span class="toc-text"> 1.伟大的第一步，确定算法基本思路</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2%E5%B0%9D%E8%AF%95%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.1.3.2.</span> <span class="toc-text"> 2.尝试实现</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3%E5%9D%87%E5%80%BC%E6%A8%A1%E7%B3%8A%E9%AB%98%E6%96%AF%E6%A8%A1%E7%B3%8A"><span class="toc-number">1.1.3.3.</span> <span class="toc-text"> 3.均值模糊&#x2F;高斯模糊</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4%E5%85%B6%E4%BB%96%E6%BB%A4%E9%95%9C"><span class="toc-number">1.1.3.4.</span> <span class="toc-text"> 4.其他滤镜</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A1%E4%BA%8C"><span class="toc-number">1.2.</span> <span class="toc-text"> 任务二</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E8%AE%A4%E8%AF%86%E5%9B%BE%E7%89%87%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB"><span class="toc-number">1.2.1.</span> <span class="toc-text"> 1.认识图片风格迁移</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E4%BD%BF%E7%94%A8pytorch%E5%AE%9E%E7%8E%B0%E5%9B%BE%E7%89%87%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB"><span class="toc-number">1.2.2.</span> <span class="toc-text"> 2.使用pytorch实现图片风格迁移</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3"><span class="toc-number">1.2.2.1.</span> <span class="toc-text"> 1.核心思想</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2%E5%8A%9F%E8%83%BD%E5%88%86%E6%AD%A5%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.2.2.2.</span> <span class="toc-text"> 2.功能分步实现</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1%E5%8A%A0%E8%BD%BD%E5%9B%BE%E7%89%87"><span class="toc-number">1.2.2.2.1.</span> <span class="toc-text"> 1.加载图片</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2%E8%AE%A1%E7%AE%97%E6%8D%9F%E5%A4%B1"><span class="toc-number">1.2.2.2.2.</span> <span class="toc-text"> 2.计算损失</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3%E9%99%8D%E4%BD%8E%E6%A2%AF%E5%BA%A6"><span class="toc-number">1.2.2.2.3.</span> <span class="toc-text"> 3.降低梯度</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4%E8%A7%84%E8%8C%83%E5%8C%96%E8%BE%93%E5%85%A5%E5%9B%BE%E5%83%8F%E4%BB%A5%E5%AF%BC%E5%85%A5nnsequential"><span class="toc-number">1.2.2.2.4.</span> <span class="toc-text"> 4.规范化输入图像以导入nn.Sequential</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#5%E8%8E%B7%E5%BE%97%E9%A3%8E%E6%A0%BC%E6%A8%A1%E5%9E%8B%E5%92%8C%E6%8D%9F%E5%A4%B1%E9%87%8F"><span class="toc-number">1.2.2.2.5.</span> <span class="toc-text"> 5.获得风格模型和损失量</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3%E5%AE%8C%E6%95%B4%E7%A4%BA%E4%BE%8B%E4%BB%A3%E7%A0%81"><span class="toc-number">1.2.2.3.</span> <span class="toc-text"> 3.完整示例代码</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%E5%BF%AB%E9%80%9F%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB"><span class="toc-number">1.2.3.</span> <span class="toc-text"> 3.快速风格迁移</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1%E4%BB%80%E4%B9%88%E6%98%AF%E5%BF%AB%E9%80%9F%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB"><span class="toc-number">1.2.3.1.</span> <span class="toc-text"> 1.什么是快速风格迁移</span></a></li></ol></li></ol></li></ol></li></ol></div></div></div><div class="card-widget card-recent-post"><div class="card-content"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2021/03/0140413.html" title="操作系统学习日记"><img data-lazy-src="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201014140049.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="操作系统学习日记"/></a><div class="content"><a class="title" href="/2021/03/0140413.html" title="操作系统学习日记">操作系统学习日记</a><time datetime="2021-03-01T08:30:00.000Z" title="发表于 2021-03-01 16:30:00">2021-03-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/12/242292.html" title="Python排序算法可视化"><img data-lazy-src="https://kevinmatt-1303917904.file.myqcloud.com/20201224145643.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Python排序算法可视化"/></a><div class="content"><a class="title" href="/2020/12/242292.html" title="Python排序算法可视化">Python排序算法可视化</a><time datetime="2020-12-24T06:55:00.000Z" title="发表于 2020-12-24 14:55:00">2020-12-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/12/1465003.html" title="Json学习笔记"><img data-lazy-src="https://kevinmatt-1303917904.cos.ap-chengdu.myqcloud.com/20201014140049.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Json学习笔记"/></a><div class="content"><a class="title" href="/2020/12/1465003.html" title="Json学习笔记">Json学习笔记</a><time datetime="2020-12-14T05:49:00.000Z" title="发表于 2020-12-14 13:49:00">2020-12-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/12/0718363.html" title="近日规划&amp;完成情况"><img data-lazy-src="https://kevinmatt-1303917904.file.myqcloud.com/20201207162714.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="近日规划&amp;完成情况"/></a><div class="content"><a class="title" href="/2020/12/0718363.html" title="近日规划&amp;完成情况">近日规划&amp;完成情况</a><time datetime="2020-12-07T08:18:35.000Z" title="发表于 2020-12-07 16:18:35">2020-12-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/12/0739258.html" title="C语言期末复习指南"><img data-lazy-src="https://kevinmatt-1303917904.file.myqcloud.com/20201221195953.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="C语言期末复习指南"/></a><div class="content"><a class="title" href="/2020/12/0739258.html" title="C语言期末复习指南">C语言期末复习指南</a><time datetime="2020-12-07T08:18:35.000Z" title="发表于 2020-12-07 16:18:35">2020-12-07</time></div></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By Kevin Matt</div><div class="footer_custom_text">Hello, welcome to Kevin's space!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.spacingElementById('content-inner')
  else {
    $.getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js', () => {
      pangu.spacingElementById('content-inner')
    })
  }
}

function panguInit () {
  if (true){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguFn)</script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>$(function () {
  $('span.katex-display').wrap('<div class="katex-wrap"></div>')
})</script><script>if (document.getElementsByClassName('mermaid').length) {
  if (window.mermaidJsLoad) mermaid.init()
  else {
    $.getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js', function () {
      window.mermaidJsLoad = true
      mermaid.initialize({
        theme: 'default',
      })
      true && mermaid.init()
    })
  }
}</script><script>function loadValine () {
  function initValine () {
    let initData = {
      el: '#vcomment',
      appId: 'dfIqaR3dlG11rExjsg8QxPSq-gzGzoHsz',
      appKey: 'qnmn7PvGee645pdcmcucnyvJ',
      placeholder: '请留下你的足迹,昵称可以使用QQ~',
      avatar: 'monsterid',
      meta: 'nick,mail,link'.split(','),
      pageSize: '10',
      lang: 'zh-CN',
      recordIP: true,
      serverURLs: 'https://dfiqar3d.lc-cn-n1-shared.com',
      emojiCDN: '',
      emojiMaps: "",
      enableQQ: true,
      path: window.location.pathname,
    }

    if (true) { 
      initData.requiredFields= ('nick,mail'.split(','))
    }
    
    if (false) {
      const otherData = false
      initData = Object.assign({}, initData, otherData)
    }
    
    const valine = new Valine(initData)
  }

  if (typeof Valine === 'function') initValine() 
  else $.getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js', initValine)
}

if ('Valine' === 'Valine' || !true) {
  if (true) btf.loadComment(document.querySelector('#vcomment'),loadValine)
  else setTimeout(() => loadValine(), 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><div class="aplayer no-destroy" data-id="5294500260" data-volume="0.3" data-server="netease" data-type="playlist" data-fixed="true" data-mini="true" data-listFolded="false" data-order="random" data-preload="none" data-autoplay="true" muted></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/HCLonely/Valine@latest/dist/Valine.min.js"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/Hexo/js/hideCategory.min.js"><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-nest.min.js"></script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-show-text.min.js" async="async" mobile="false"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/gh/metowolf/MetingJS@1.2/dist/Meting.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = [
  'title',
  '#config_change',
  '#body-wrap',
  '#rightside-config-hide',
  '#rightside-config-show',
  '.js-pjax'
]

if (false) {
  pjaxSelectors.unshift('meta[property="og:image"]', 'meta[property="og:title"]', 'meta[property="og:url"]')
}

var pjax = new Pjax({
  elements: 'a:not([target="_blank"]):not([href="/music/"]):not([href="/no-pjax/"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  $('script[data-pjax]').each(function () {
    $(this).parent().append($(this).remove())
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  if (typeof gtag === 'function') {
    gtag('config', '', {'page_path': window.location.pathname});
  }

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // Analytics
  if (false) {
    MtaH5.pgv()
  }

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()

  typeof preloader === 'object' && preloader.endLoading()
})


document.addEventListener('pjax:send', function () {
  typeof preloader === 'object' && preloader.initLoading()
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  $(window).off('scroll')

  //reset readmode
  $('body').hasClass('read-mode') && $('body').removeClass('read-mode')

})</script></div></body></html>